{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_1(X):\n",
    "    X.set_index('id',inplace=True)\n",
    "    #Time features\n",
    "    date_stack = np.vstack(X.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "    X['year'] = date_stack[:,0]\n",
    "    X['month'] = date_stack[:,1]\n",
    "    X['day']  = date_stack[:,2]\n",
    "    \n",
    "    X['timestamp_first_active'] = X.timestamp_first_active//1000000\n",
    "    \n",
    "    tfa = np.vstack(X.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8]]))).values)\n",
    "    \n",
    "    X['tfa_year'] = tfa[:,0]\n",
    "    X['tfa_month']  = tfa[:,1]\n",
    "    X['tfa_day']   = tfa[:,2]\n",
    "    \n",
    "    X['date_account_created'] = X.date_account_created.astype(str).apply(lambda x:int(x.replace(\"-\",\"\")))\n",
    "    \n",
    "    X['timediff'] = X.date_account_created - X.timestamp_first_active\n",
    "    \n",
    "    X.drop(['timestamp_first_active','date_account_created','date_first_booking'],axis=1,inplace=True)\n",
    "    \n",
    "    ## Age feature\n",
    "    \n",
    "    X['age'] = X['age'].apply(lambda x: 2015 - x if x >1900 else x)\n",
    "    X['age'].fillna(-1,inplace=True)\n",
    "    \n",
    "    feat_onehot = ['gender','signup_method','signup_flow','language','affiliate_channel','affiliate_provider','signup_app','first_affiliate_tracked','first_device_type','first_browser']\n",
    "    \n",
    "    for f in feat_onehot:\n",
    "        df_dummy = pd.get_dummies(X[f],prefix=f)\n",
    "        X = X.drop([f],axis=1)\n",
    "        X = pd.concat((X,df_dummy),axis=1)\n",
    "    \n",
    "    #reading the important column names which are recognized by our model\n",
    "    with open('imp_colnames.pkl','rb') as f:\n",
    "        imp_col_names = pickle.load(f)\n",
    "        \n",
    "    \n",
    "    X = X[X.columns[X.columns.isin(imp_col_names)]]\n",
    "    \n",
    "    extra_features = list(set(imp_col_names)-set(X.columns.to_list()))\n",
    "    \n",
    "    \n",
    "    for i in extra_features:\n",
    "         X[i] = np.nan\n",
    "            \n",
    "    X.reindex(columns=imp_col_names)\n",
    "    X.fillna(0,inplace=True)\n",
    "    \n",
    "    classifier = pickle.load(open('stackingclf.pickle.dat','rb'))\n",
    "    \n",
    "    pred_probab = classifier.predict_proba(X[imp_col_names])\n",
    "    \n",
    "    # storing the predictions of each user_id in a dataframe with user_id as the index\n",
    "    pred_probab_df = pd.DataFrame(pred_probab,index=X.index)\n",
    "    \n",
    "    output_classes = {'AU': 0,\n",
    "    'CA': 1,\n",
    "    'DE': 2,\n",
    "    'ES': 3,\n",
    "    'FR': 4,\n",
    "    'GB': 5,\n",
    "    'IT': 6,\n",
    "    'NDF': 7,\n",
    "    'NL': 8,\n",
    "    'PT': 9,\n",
    "    'US': 10,\n",
    "    'other': 11}\n",
    "    \n",
    "    # inverting the dictionary\n",
    "    inv_classes = {v:k for k,v in output_classes.items()}\n",
    "    \n",
    "    def top_5_countries(s):\n",
    "        \"\"\"\n",
    "        This function takes the probability values of each id, sorts the top 5 values and using an inverse dictionary(inv_classes) gives the top 5 countries prediction.\n",
    "        \"\"\"\n",
    "        indices = np.arange(0,12)\n",
    "        pred_dict = dict(zip(indices,s))\n",
    "        sorted_abc = sorted(pred_dict.items(),key=lambda x:x[1],reverse=True)[:5]\n",
    "        row_indices = [x[0] for x in sorted_abc]\n",
    "        top_five = [inv_classes[i] for i in row_indices]\n",
    "        return top_five\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    # here we apply the above function on each row of the dataframe to get the top 5 prediction.\n",
    "    pred_probab_df['top_five'] = pred_probab_df.apply(top_5_countries,axis=1)  \n",
    "    \n",
    "    submission = pred_probab_df.drop([i for i in range(0,12)],axis=1)\n",
    "    \n",
    "    return submission.head()\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Enter Your Train/Test set csv file path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = final_fun_1(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_five</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5uwns89zht</th>\n",
       "      <td>[NDF, US, other, FR, IT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jtl0dijy2j</th>\n",
       "      <td>[NDF, US, other, FR, IT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xx0ulgorjt</th>\n",
       "      <td>[NDF, US, other, FR, IT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6c6puo6ix0</th>\n",
       "      <td>[NDF, US, other, FR, IT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>czqhjk3yfe</th>\n",
       "      <td>[NDF, US, other, FR, IT]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            top_five\n",
       "id                                  \n",
       "5uwns89zht  [NDF, US, other, FR, IT]\n",
       "jtl0dijy2j  [NDF, US, other, FR, IT]\n",
       "xx0ulgorjt  [NDF, US, other, FR, IT]\n",
       "6c6puo6ix0  [NDF, US, other, FR, IT]\n",
       "czqhjk3yfe  [NDF, US, other, FR, IT]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labelsfull.pkl','rb') as f:\n",
    "    Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_fun_2(X,Y):\n",
    "    X.set_index('id',inplace=True)\n",
    "    #Time features\n",
    "    date_stack = np.vstack(X.date_account_created.astype(str).apply(lambda x: list(map(int, x.split('-')))).values)\n",
    "    X['year'] = date_stack[:,0]\n",
    "    X['month'] = date_stack[:,1]\n",
    "    X['day']  = date_stack[:,2]\n",
    "    \n",
    "    X['timestamp_first_active'] = X.timestamp_first_active//1000000\n",
    "    \n",
    "    tfa = np.vstack(X.timestamp_first_active.astype(str).apply(lambda x: list(map(int, [x[:4],x[4:6],x[6:8]]))).values)\n",
    "    \n",
    "    X['tfa_year'] = tfa[:,0]\n",
    "    X['tfa_month']  = tfa[:,1]\n",
    "    X['tfa_day']   = tfa[:,2]\n",
    "    \n",
    "    X['date_account_created'] = X.date_account_created.astype(str).apply(lambda x:int(x.replace(\"-\",\"\")))\n",
    "    \n",
    "    X['timediff'] = X.date_account_created - X.timestamp_first_active\n",
    "    \n",
    "    X.drop(['timestamp_first_active','date_account_created','date_first_booking'],axis=1,inplace=True)\n",
    "    \n",
    "    ## Age feature\n",
    "    \n",
    "    X['age'] = X['age'].apply(lambda x: 2015 - x if x >1900 else x)\n",
    "    X['age'].fillna(-1,inplace=True)\n",
    "    \n",
    "    feat_onehot = ['gender','signup_method','signup_flow','language','affiliate_channel','affiliate_provider','signup_app','first_affiliate_tracked','first_device_type','first_browser']\n",
    "    \n",
    "    for f in feat_onehot:\n",
    "        df_dummy = pd.get_dummies(X[f],prefix=f)\n",
    "        X = X.drop([f],axis=1)\n",
    "        X = pd.concat((X,df_dummy),axis=1)\n",
    "    \n",
    "    #reading the important column names which are recognized by our model\n",
    "    with open('imp_colnames.pkl','rb') as f:\n",
    "        imp_col_names = pickle.load(f)\n",
    "        \n",
    "    \n",
    "    X = X[X.columns[X.columns.isin(imp_col_names)]]\n",
    "    \n",
    "    extra_features = list(set(imp_col_names)-set(X.columns.to_list()))\n",
    "    \n",
    "    \n",
    "    for i in extra_features:\n",
    "         X[i] = np.nan\n",
    "            \n",
    "    X.reindex(columns=imp_col_names)\n",
    "    X.fillna(0,inplace=True)\n",
    "    \n",
    "    classifier = pickle.load(open('stackingclf.pickle.dat','rb'))\n",
    "    \n",
    "    pred_probab = classifier.predict_proba(X[imp_col_names])\n",
    "    \n",
    "    # storing the predictions of each user_id in a dataframe with user_id as the index\n",
    "    \n",
    "    def dcg_score(y_true, y_score, k=5):\n",
    "        order = np.argsort(y_score)[::-1]\n",
    "        y_true = np.take(y_true, order[:k])\n",
    "        gain = 2 ** y_true - 1\n",
    "        discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "        return np.sum(gain / discounts)\n",
    "    \n",
    "    def ndcg_score(ground_truth, predictions, k=5):\n",
    "        lb = LabelBinarizer()\n",
    "        lb.fit(range(len(predictions[0]) + 1))\n",
    "        T = lb.transform(ground_truth)\n",
    "        scores = []\n",
    "        \n",
    "        for y_true, y_score in zip(T, predictions):\n",
    "            actual = dcg_score(y_true, y_score, k)\n",
    "            best = dcg_score(y_true, y_true, k)\n",
    "            \n",
    "            if best <= 0:\n",
    "                 score = 0.0\n",
    "            else:\n",
    "                 score = float(actual) / float(best)\n",
    "            scores.append(score)\n",
    "            \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    metric_value = ndcg_score(Y,pred_probab)\n",
    "    \n",
    "    return metric_value\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('Enter your (Train or Test) csv file path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels\n",
    "with open('labelsfull.pkl','rb') as f:\n",
    "    Y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = final_fun_2(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value is: 0.7683478952898508\n"
     ]
    }
   ],
   "source": [
    "print(\"The value is:\",value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
